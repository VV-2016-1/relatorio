\chapter[Referencial]{Referencial Teórico}

\section{Verificação e validação}
\section{Qualidade de Testes}
Quando se trata de manufatura ou produção de componentes físicos, os testes
sobre a confiabilidade do que foi produzido é feito a partir de uma porcentagem
do lote retirado do todo. Caso a quantidade retirada do lote passe nos testes,
este é aprovado, caso não, todas peças são rejeitadas.

Ao se tratar de software, a maneira de executar os testes é bastante diferente.
Cada software tem a sua peculiaridade e é desenvolvido de acordo com as
capacidades dos desenvolvedores participantes do projeto. \cite{e08}, em seu estudo,
afirma que antigamente eram realizados os testes com base nos testes de hardware.
E, que esses, por sua vez, não eram realísticos.

Dessa maneira, há a necessidade de que este produto tenha seus testes específicos,
partindo desde o menor nível possível, passando pela sua integração e chegando
no momento do uso do produto pelo usuário.
Os softwares são desenvolvidos e assim, uma bateria de testes é definida no
documento de casos de teste. Vários testes são  executados de acordo com o sistema,
podendo ser entrem eles testes de:

\begin{itemize}
\item Testes Unitários
\item Testes de Integração
\item Testes de Sistema
\item Testes de Aceitação
\item Testes de Instalação
\end{itemize}

Mas algumas perguntas que sempre intrigou os programadores responsáveis pelos testes são:

\begin{itemize}
\item O quanto eu devo testar de maneira que o software esteja suficientemente
confiável?
\item Quais são os pontos necessários a ponderar para entender o conceito
de confiabilidade dos meus testes, por consequência, do meu software?
\end{itemize}

\cite{e07} produziu um estudo que informa várias formas de se verificar a atestar
a qualidade dos testes de software executados. E todas as suas maneiras de identicar
estes pontos é partindo de dois princípios:

\begin{itemize}
\item Avaliação do plano de testes, verificando se todos os requisitos foram
descritos no caso de testes e se todos os testes e seus múltiplos casos foram
contemplados na implementação.
\item Associação dos testes cobrindo tudo o que foi implementado como requisito
do sistema.
\end{itemize}

Assim, ele estabeleceu duas métricas que possibilitam aferir a confiabilidade
dos testes de um software. Sendo elas:

\begin{enumerate}
\item Número de casos de teste implementados / número de casos de teste estimados.
\item Cobertura do código
\end{enumerate}

Dessa maneira, a organização consegue aferir números sobre a confiabilidade
da implementação dos testes a partida da aplicação dos resultados obtidos  \cite{e07}

\section{Integração Contínua}
Uma prática utilizada para eliminar descontinuidades entre o desenvolvimento e a implantação é a integração contínua \cite{roadmap}. A integração contínua é bastante utilizada atualmente devido ao avanço das metodologias ágeis, e consiste de uma prática na qual os desenvolvedores de software trabalham em pequenos incrementos, assim, eles contribuem com o código frequentemente e garantem que o projeto compile e passe a suíte de testes a qualquer momento \cite{opensource}.

O uso da integração contínua apresenta várias vantagens, ela aumenta a frequência de lançamento de software, a previsibilidade, a produtividade do desenvolvedor, entre outros \cite{practice}.

Sendo assim, ao utilizar essa prática, incrementos de software serão lançados com uma frequência alta. Diante disso, uma questão importante é sobre como validar tantos incrementos. Para resolver esse problema existem ferramentas que auxiliam a realização da integração contínua. O que é essencial para a automatização da integração contínua, é o uso de um repositório para o código, assim ferramentas como Git ou Subversion são úteis. Além disso, existem ferramentas analisam as novas mudanças de código enviadas, elas checam o código a fim de verificar se aquela mudança de código é boa e não "quebra"  nenhuma outra funcionalidade ou teste \cite{meyer}, nesse caso, ferramentas como Travis, Jenkins ou GitLab Ci auxiliam esse processo.

